<html>
<head>
  <title>Report 4.1.1 — AI/LLM Integration Detail</title>
  <style>
  body { font-family: 'Segoe UI', Arial, sans-serif; background: #fafbfc; color: #23272f; margin: 0; padding: 0; }
  .container { max-width: 950px; margin: 40px auto; background: #fff; box-shadow: 0 8px 32px rgba(0,0,0,0.08); border-radius: 10px; padding: 32px 40px; }
  h1 { color: #1565c0; }
  h2 { color: #2e7d32; margin-top: 32px; }
  h3 { color: #7b1fa2; margin-top: 24px; }
  .note { background: #e3f2fd; border-left: 4px solid #1976d2; padding: 16px 20px; margin: 18px 0; border-radius: 7px; }
  .note ul { list-style: disc inside; margin: 0; padding-left: 1.2em; }
  .note li { margin-bottom: 3px; line-height: 1.35; }
  .note p { margin: 0 0 6px 0; line-height: 1.5; }
  .footer { text-align: right; color: #888; font-size: 1em; margin-top: 40px; }
  .tag { background: #e3f2fd; color: #1565c0; border-radius: 4px; padding: 3px 8px; margin-left: 6px; font-size: 0.95em; }
  dt { color: #2e7d32; font-weight: bold; margin-top: 10px; }
  dd { margin-bottom: 10px; }
  .params table { border-collapse: collapse; width: 100%; margin: 10px 0; }
  .params th, .params td { border: 1px solid #ccc; padding: 6px; }
  .important { background: #fffde7; border-left: 4px solid #fbc02d; padding: 12px 18px; margin: 18px 0; border-radius: 5px; }
  .sideEffects ul, .solid ul { margin: 0; padding-left: 20px; }
  @media (max-width: 600px) { .container { padding: 16px 8px; } }
  pre { background: #f6f8fa; padding: 14px; border-radius: 8px; overflow: auto; font-size: 0.92em; }
  code { font-family: Consolas, 'Courier New', monospace; }
  .row { display:flex; gap:20px; flex-wrap:wrap; }
  .col { flex:1 1 420px; }
  .endpoint { border: 1px solid #e0e0e0; padding: 12px 14px; border-radius: 8px; background: #fff; box-shadow: 0 3px 8px rgba(0,0,0,0.04); }
  .json { white-space: pre; font-family: Consolas, 'Courier New', monospace; font-size: 0.95em; }
  .success { color: #2e7d32; font-weight: 600; }
  .error { color: #c62828; font-weight: 600; }
  </style>
</head>
<body>
  <div class="container">
    <h1>Report 4.1.1 — AI/LLM Integration <span class="tag">Detailed Guide</span></h1>
    <p>This write-up documents how AI/LLM capabilities are integrated into the project to intelligently extract action items from meeting transcripts.</p>

    <section>
      <h2>End-to-End Flow</h2>
      <p>The pipeline for transcript-based action-item extraction is:</p>
      <ol>
        <li><strong>OpenAITestController</strong> receives the transcript (via REST request). It forwards the text to <code>ActionItemExtractorService</code>.</li>
        <li><strong>ActionItemExtractorService</strong> crafts a prompt that asks OpenAI to emit a JSON array of objects with keys: <code>description</code>, <code>priority</code>, <code>deadline</code>, <code>assignee</code>, <code>category</code>. This structured output ensures HubSpot receives usable data.</li>
        <li><strong>OpenAIService</strong> posts the prompt to <code>https://api.openai.com/v1/chat/completions</code> using <code>gpt-4o-mini</code>. The method captures HTTP timing (start/end Instant) to calculate execution duration and annotate the response map with metadata (<code>executionTimestamp</code>, <code>executionDurationMs</code>).</li>
        <li>Responses are returned to the extractor, which trims markdown fences (handles triple-backtick JSON) and parses the string via Jackson into a list of action-item maps.</li>
        <li>For malformed or empty responses, the extractor captures the raw string under a <code>raw_output</code> key so the downstream caller can still report partial data.</li>
        <li><strong>HubSpotTaskService</strong> receives the parsed action items, maps them onto the HubSpot property schema (<code>ai_systems_description</code>, <code>ai_systems_deadline</code>, etc.), and POSTs each as part of the <code>/crm/v3/objects/deals</code> flow.</li>
      </ol>
    </section>

    <section>
      <h2>Prompt & Parsing Details</h2>
      <div class="note">
        <h3>Prompt Strategy</h3>
        <ul>
          <li>Include explicit fields and format instructions to coax consistent JSON output.</li>
          <li>Request priority in (HIGH/MEDIUM/LOW) canonical values for easy mapping.</li>
          <li>Ask for deadlines and assignees to minimize downstream interpretation logic.</li>
        </ul>
      </div>
      <div class="note">
        <h3>Parsing Strategy</h3>
        <ul>
          <li>Strip Markdown code fences that OpenAI sometimes wraps around JSON.</li>
          <li>Attempt JSON parsing via Jackson; on failure, store raw response so operators can inspect it.</li>
          <li>Fallback path ensures downstream HubSpot creation still runs but records the entire payload (even if unparsable) for debugging.</li>
        </ul>
      </div>
    </section>

    <section>
      <h2>Observability & Metadata</h2>
      <p>Every OpenAI interaction records metadata by augmenting the returned map with:</p>
      <ul>
        <li><code>executionTimestamp</code>: ISO instant captured after the API call.</li>
        <li><code>executionDurationMs</code>: Milliseconds between start and finish for SLA tracking.</li>
      </ul>
      <div class="important">
        <p>This metadata allows the automation runner and any monitoring dashboards to surface latency spikes in the AI extraction path.</p>
      </div>
    </section>

    <section>
      <h2>Error Handling & Robustness</h2>
      <ul>
        <li><strong>Retries:</strong> The controller retries completions with stronger instructions if the primary response is empty.</li>
        <li><strong>JSON Fallbacks:</strong> Parser gracefully handles partial data by logging errors and preserving raw strings.</li>
        <li><strong>Fallback DTOs:</strong> Action items include unexpected responses so the same processing pipeline still executes.</li>
      </ul>
    </section>

    <div class="footer">Generated detailed documentation for 4.1.1 AI/LLM integration</div>
  </div>
</body>
</html>
